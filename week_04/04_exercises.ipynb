{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Numerical operations, data handling, data visualization\n",
    "\n",
    "\n",
    "**Setup**: make sure you've completed the instructions in the README for this week!\n",
    "\n",
    "\n",
    "This exercise attempts to be a pedagogical introduction to some key libraries in\n",
    "scientific programming.  \n",
    "\n",
    "Unlike the wet lab, it is very hard to break things or blow things up in a notebook. To\n",
    "get the most of these coding exercises, try things out and experiment with the code!\n",
    "\n",
    "Learning some cool things usually starts with a question \n",
    "\n",
    "\n",
    "## 0. Introduction\n",
    "\n",
    "Numpy, pandas, and matplotlib are three of the most widely used libraries in the Python\n",
    "data science ecosystem. Each serves a distinct purpose in data manipulation, analysis,\n",
    "and visualization, making them indispensable tools for scientists, including those in\n",
    "the chemical sciences.\n",
    "\n",
    "* `numpy` is used for efficient array operations and matrix manipulation, and statistical\n",
    "functions.\n",
    "* `pandas` is used for making data tables, and reading, writing and manipulation from\n",
    "  them.\n",
    "* `matplotlib` is used for creating high quality plots and figures.\n",
    "\n",
    "\n",
    "Each will be covered in more detail below. But first, we need to import these modules.\n",
    "With `import x as y` below, we import the package `x` with an ***alias*** `y`. The\n",
    "aliases shown below are community conventions for these packages (i.e. `np` for numpy,\n",
    "`pd` for `pandas` and `plt` for matplotlib). \n",
    "\n",
    "These are important to be aware of, as oftentimes help pages online (for instance, if\n",
    "you are trying to find a solution to a problem on Stack Exchange) may use these\n",
    "aliases without explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** if you get a `ModuleNotFound` error, make sure you have gone through this\n",
    "week's README first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Numerical operations with `numpy`\n",
    "\n",
    "**What is is**: Numpy (Numerical Python) is a library for numerical computing in Python.\n",
    "It provides support for large, multi-dimensional arrays and matrices, along with a\n",
    "collection of mathematical functions to operate on these arrays efficiently.\n",
    "\n",
    "**Why it's used**: Numpy is fundamental for scientific computing due to its powerful\n",
    "data structures, which enable high-performance calculations and data analysis. It serves\n",
    "as the backbone for many other Python data analysis libraries, including pandas and many\n",
    "machine learning frameworks.\n",
    "\n",
    "**Usefulness in Chemical Science**: In chemistry, numpy is essential for handling\n",
    "numerical data such as molecular structures, quantum mechanical properties, and large\n",
    "datasets generated from simulations or experimental measurements. Its efficiency in\n",
    "performing vectorized operations makes it ideal for computational chemistry tasks,\n",
    "including molecular dynamics simulations and numerical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized operations: faster than `for` loops\n",
    "\n",
    "In previous exercises, you were introduced to for loops as a way to repeatedly execute a\n",
    "block of code for a specified number of times or over a sequence. NumPy operations allow\n",
    "for vectorized processing of data arrays, often replacing the need for for loops with\n",
    "more efficient and concise array-based calculations. They work by ***parallelizing**\n",
    "operations.\n",
    "\n",
    "**Introduction to `%%timeit`**: The `%%timeit` magic command in Jupyter Notebooks is\n",
    "used to measure the execution time of a code block. It runs the code several times in a\n",
    "loop to get an accurate average time, helping you understand the performance of your\n",
    "code. This is particularly useful when comparing the speed of different approaches to\n",
    "solving the same problem.\n",
    "\n",
    "Let's compare the time it takes to sum elements in a list, with for-loops versus\n",
    "`numpy`.\n",
    "\n",
    "First, create a large list as the following, which gives a list of the form `[0, 1, ...,\n",
    "999998, 999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_elements = 1000000\n",
    "large_list = list(range(num_elements))\n",
    "\n",
    "print(large_list[:5])  # list indexing as usual\n",
    "print(large_list[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to sum the elements in the list. For the `numpy` version, we use the\n",
    "function `np.sum` to sum the elements in the list. When using a function from an\n",
    "external module, it is a good idea to read the documentation to understand what it does.\n",
    "\n",
    "In jupyter notebooks, you can write the name of the function followed by `?` to print\n",
    "the documentation. There's a lot going here, but the important part is the signature and\n",
    "the description:\n",
    "```\n",
    "Signature:      \n",
    "np.sum(\n",
    "    a,\n",
    "    axis=None,\n",
    "    dtype=None,\n",
    "    out=None,\n",
    "    keepdims=<no value>,\n",
    "    initial=<no value>,\n",
    "    where=<no value>,\n",
    ")\n",
    "...\n",
    "Sum of array elements over a given axis.\n",
    "```\n",
    "\n",
    "You can also find the docs online. Google: \"numpy sum\" and navigate to (hopefully) the\n",
    "top result, i.e. https://numpy.org/doc/stable/reference/generated/numpy.sum.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python for loops\n",
    "def sum_python_loop(data) -> float:\n",
    "    \"\"\"Sum the elements in `data` using a for loop\"\"\"\n",
    "    total = 0\n",
    "    for x in data:\n",
    "        total += x\n",
    "    return total\n",
    "\n",
    "\n",
    "# Numpy sum\n",
    "def sum_numpy(data) -> float:\n",
    "    \"\"\"Sum the elements in `data` using numpy\"\"\"\n",
    "    return np.sum(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now uncomment the cells below and run them. What do you notice about the timings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sum_python_loop(large_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sum_numpy(large_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, it appears that the Python for loop is faster here! Why? Aren't vectorized\n",
    "operations supposed to be quicker than for loops?\n",
    "\n",
    "Let's try again, but instead of summing elements in a list let's store our data in a\n",
    "numpy `array` instead. Here we used the `np.arange` function to generate an array of\n",
    "integers in the range `0, ... (n_elements - 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_array = np.arange(num_elements)\n",
    "\n",
    "print(large_array[:5])  # array indexing just like list indexing\n",
    "print(large_array[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sum_python_loop(large_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sum_numpy(large_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better!\n",
    "\n",
    "In the first example, the `np.sum` function first converts the list in `large_list` to a\n",
    "numpy `array`, which has a large associated overhead cost. This makes the timings\n",
    "comparable between the for loop approach and the numpy approach. However, by first\n",
    "storing our data in a `np.array` in the second example, we gain access to the efficient\n",
    "array operations in `numpy`. If we store and pass around data in numpy arrays in all of\n",
    "our programs, we only have to consider the overhead costs once.\n",
    "\n",
    "In general, Python lists are versatile and useful: they can be dynamically-sized and\n",
    "collect together elements with different data types.\n",
    "\n",
    "However, if we are dealing with data whose size we know, and whose data types are\n",
    "homogenous (in this case `int`), using instead a NumPy array will give us far enhanced\n",
    "performance in numerical computations versus for loops. For specific applications in\n",
    "chemistry that are computation-intensive, like data analysis, visualization, and machine\n",
    "learning, we often want to work with arrays.\n",
    "\n",
    "Let's explore more examples of array-based operations with numpy.\n",
    "\n",
    "\n",
    "### Summing lists / arrays\n",
    "\n",
    "Let's create two lists of the same size and sum them element-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a = list(range(1000000))\n",
    "list_b = list(range(1, 1000001))\n",
    "\n",
    "def add_python_loop(list1: list, list2: list) -> list:\n",
    "    return [x + y for x, y in zip(list1, list2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the function returns\n",
    "new_list = add_python_loop(list_a, list_b)\n",
    "print(new_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit  # now time it\n",
    "add_python_loop(list_a, list_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_a = np.arange(1000000)  # integers from 0 to 999999\n",
    "array_b = np.arange(1, 1000001)  # integers from 1 to 1000000\n",
    "\n",
    "def add_numpy_arrays(array_1: np.ndarray, array_2: np.ndarray) -> np.ndarray:\n",
    "    return array_1 + array_2  # you can just use the + operator here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the function returns\n",
    "new_array = add_numpy_arrays(array_a, array_b)\n",
    "print(new_array[:10])\n",
    "\n",
    "# Use the `.shape` attribute to see the shapes of the arrays\n",
    "print(array_a.shape, array_b.shape, new_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit  # now time it\n",
    "add_numpy_arrays(array_a, array_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing numpy arrays\n",
    "\n",
    "In NumPy, multi-dimensional arrays (also known as ndarrays) are the foundation for most\n",
    "of the library's operations, allowing you to efficiently store and manipulate data\n",
    "across multiple dimensions. Creating multi-dimensional arrays in NumPy is\n",
    "straightforward, enabling the handling of complex data structures like matrices for\n",
    "linear algebra, tensors for machine learning, or grids for scientific computing.\n",
    "\n",
    "You can create multi-dimensional arrays in NumPy using various methods, including\n",
    "np.array, np.zeros, np.ones, and np.arange, among others. Here are some examples to get\n",
    "you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D array (matrix)\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(matrix)\n",
    "\n",
    "# Create a 2x3 array of zeros\n",
    "zeros_array = np.zeros((2, 3))\n",
    "print(zeros_array)\n",
    "\n",
    "# Create a 3x3x3 array of ones\n",
    "ones_array = np.ones((3, 3, 3))\n",
    "print(ones_array)\n",
    "\n",
    "# Create a 3x4 array with a range of numbers\n",
    "range_array = np.arange(12).reshape(3, 4)\n",
    "print(range_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, you'll need to reshape an array into a different dimension. This is done using\n",
    "the .reshape() method, which allows you to specify the new shape as long as the total\n",
    "number of elements remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape a 1D array into a 2D array\n",
    "one_d_array = np.arange(6)\n",
    "two_d_array = one_d_array.reshape((2, 3))\n",
    "print(one_d_array)\n",
    "print(two_d_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from file into numpy arrays\n",
    "\n",
    "To illustrate how to read chemical data from a file using `np.loadtxt`, let's consider a\n",
    "simple example where we have a file containing molecular weights of several compounds,\n",
    "stored in the file \"molecular_weights.txt\". \n",
    "\n",
    "The data file is organized with the name of the compound in one column and its molecular\n",
    "weight in the other. For this example, let's assume we are only interested in the\n",
    "numerical data (molecular weights) and that our data file is structured with comments\n",
    "marked by \"#\" and values separated by commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data file\n",
    "file_path = 'molecular_data.txt'\n",
    "\n",
    "# Note that if we try to load the entire file into a single array, we'll get an error as\n",
    "# the file contains both strings and floats. Here, we use delimiter=',' to handle the\n",
    "# comma-separated values\n",
    "np.loadtxt(file_path, delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As numpy arrays must be homogenously typed, i.e. we can't mix strings and floats. We\n",
    "# can pass the `dtype` argument to `np.loadtxt` to specify the data type of the array,\n",
    "# ensuring everything is loaded as strings. However, this perhaps isn't so useful as we\n",
    "# want the molecular weights as floats.\n",
    "np.loadtxt(file_path, delimiter=',', skiprows=1, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead, we can load the names as strings and the molecular weights as floats using\n",
    "# the `usecols` argument to specify which columns to load.\n",
    "names = np.loadtxt(file_path, delimiter=',', skiprows=1, usecols=[0], dtype=str)\n",
    "molecular_weights = np.loadtxt(file_path, delimiter=',', skiprows=1, usecols=[1], dtype=np.float64)\n",
    "\n",
    "print(\"Names:\")\n",
    "print(names)\n",
    "print(\"Molecular Weights (g/mol):\")\n",
    "print(molecular_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some basic statistical analysis on the molecular weight data, by finding the\n",
    "range of values, and the mean and standard deviation.\n",
    "\n",
    "For the mean and standard deviation, perform a Google search to identify the appropriate\n",
    "numpy functions to use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find the mean and standard deviation of the molecular weights\n",
    "\n",
    "max_value = np.max(molecular_weights)\n",
    "min_value = np.min(molecular_weights)\n",
    "mean_value = ... # your code here\n",
    "std_value = ...  # your code here\n",
    "\n",
    "print(f\"Max: {max_value}, Min: {min_value}, Mean: {mean_value}, Std: {std_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which molecule has the highest molecular weight? We want to find the index in the\n",
    "# `names` array where the maximum value in `molecular_weights` is located.\n",
    "\n",
    "# We can use the `np.argmax` function to find the index of the maximum value in an\n",
    "# array.\n",
    "max_index = np.argmax(molecular_weights)\n",
    "\n",
    "print(f\"The molecule with the highest molecular weight is: {names[max_index]} with a weight of {molecular_weights[max_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data handling with `pandas`\n",
    "\n",
    "**What it is**: Pandas is a library providing high-level data structures and tools designed to make data analysis fast and easy in Python. Its primary data structure is the DataFrame, which allows you to store and manipulate tabular data in rows of observations and columns of variables.\n",
    "\n",
    "**Why it's used**: Pandas is used for data cleaning, transformation, and analysis. It offers data structures with a lot of flexibility and functionality, as well as the means to efficiently handle missing data, merge datasets, and perform complex data aggregations.\n",
    "\n",
    "**Usefulness in Chemical Sciences**: For chemists, pandas is invaluable for manipulating\n",
    "and analyzing experimental datasets, such as spectroscopy data or chemical properties of\n",
    "compounds. It simplifies tasks such as filtering data, performing statistical analyses,\n",
    "and working with time-series data from instrumental measurements.\n",
    "\n",
    "\n",
    "### Basics\n",
    "\n",
    "Pandas has two main data structures: Series and DataFrame. A Series is essentially a\n",
    "column, while a DataFrame is a multi-dimensional table made up of a collection of\n",
    "Series.\n",
    "\n",
    "A Series in pandas is one of the core data structures in the Python pandas library. It\n",
    "represents a one-dimensional array-like object containing a sequence of values and an\n",
    "associated array of data labels, called its index. The Series can hold any data\n",
    "type—integers, strings, floating point numbers, Python objects, and so on. It’s similar\n",
    "to a column in a spreadsheet or a table in a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds = pd.Series([\"Water\", \"Ethanol\", \"Glucose\", \"Sodium Chloride\", \"Methane\"])\n",
    "compounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame is a two-dimensional, size-mutable, potentially heterogeneous tabular data\n",
    "structure with labeled axes (rows and columns). For a chemistry application, let’s\n",
    "consider a simple example where we have a dataset of several compounds with their\n",
    "molecular weights and melting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Compound\": [\"Water\", \"Ethanol\", \"Glucose\", \"Sodium Chloride\", \"Methane\"],\n",
    "    \"Molecular Weight\": [18.015, 46.07, 180.16, 58.44, 16.04],\n",
    "    \"Melting Point (°C)\": [0, -114.1, 146, 801, -182.5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataFrame` can also be created by reading in data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from the molecular_weights.txt file from before\n",
    "df = pd.read_csv(file_path, )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to access a single column, we can use the column name as an attribute\n",
    "df[\"Molecular Weight (g/mol)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, inclusion of the units in the column name may make it pretty inconvenient to\n",
    "reference over and over again.\n",
    "\n",
    "We can instead load the data with custom column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data again, but this time specify the column names\n",
    "df = pd.read_csv(file_path, names=[\"molecule\", \"weight\", \"boiling_point_celsius\"], skiprows=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data inspection\n",
    "\n",
    "Pandas provides numerous functions to quickly inspect your data:\n",
    "\n",
    "* `df.head()` displays the first few rows of the DataFrame.\n",
    "* `df.describe()` gives a statistical summary of the numerical columns.\n",
    "* `df.dtypes` shows the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "In pandas, .loc and .iloc are indexing operators used for selecting data from a\n",
    "DataFrame. While both are used for data selection, they differ in how they perform the\n",
    "selection:\n",
    "\n",
    "* `.loc` is label-based, meaning you use the labels of the rows and columns to select data.\n",
    "* `.iloc` is integer position-based, so you use integer indices to select data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the row for Carbon Dioxide (index 1)\n",
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows for Water and Methanol\n",
    "df.loc[[0, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows for Water and Methane\n",
    "df.iloc[[0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Molecular Weight and Melting Point for Carbon Dioxide and Methane\n",
    "df.iloc[[1, 2], [1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the row for water\n",
    "df[df[\"molecule\"] == \"Water\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the hydrocarbons\n",
    "hydrocarbons = [\n",
    "    \"Methane\",\n",
    "    \"Ethane\",\n",
    "    \"Propane\",\n",
    "    \"Butane\",\n",
    "    \"Pentane\",\n",
    "    \"Hexane\",\n",
    "    \"Heptane\",\n",
    "    \"Octane\",\n",
    "    \"Nonane\",\n",
    "    \"Decane\",\n",
    "]\n",
    "\n",
    "df[df[\"molecule\"].isin(hydrocarbons)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecular_weights = df[\"weight\"]\n",
    "\n",
    "print(\"Max molecular weight:\", molecular_weights.max())\n",
    "print(\"Min molecular weight:\", molecular_weights.min())\n",
    "\n",
    "print(\"Mean molecular weight (pandas):\", molecular_weights.mean())\n",
    "print(\"Mean molecular weight (numpy):\", np.mean(molecular_weights))\n",
    "\n",
    "print(\"Standard deviation of molecular weight (pandas):\", molecular_weights.std())\n",
    "print(\"Standard deviation of molecular weight (numpy):\", np.std(molecular_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Bonus:*** why are the standard deviations different between numpy and pandas? Have a\n",
    "read of the respective documentation to see how the expressions are normalized:\n",
    "\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.std.html\n",
    "* https://numpy.org/doc/stable/reference/generated/numpy.std.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column of transformed data\n",
    "df[\"boiling_point_kelvin\"] = df[\"boiling_point_celsius\"].apply(lambda x: x + 274.15)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by boiling point, low to high\n",
    "df.sort_values(by=\"boiling_point_celsius\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by boiling point, high to low\n",
    "df.sort_values(by=\"boiling_point_celsius\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization with `matplotlib`\n",
    "\n",
    "**What it is**: Matplotlib is a plotting library for Python, providing an object-oriented API for embedding plots into applications. It's capable of producing a wide range of static, animated, and interactive visualizations in a variety of output formats.\n",
    "\n",
    "**Why it's used**: Matplotlib is the go-to library for creating graphs, charts, and figures in Python. It's highly customizable and can produce almost any kind of visualization you might need, from simple bar charts and line plots to complex scatter plots and histograms.\n",
    "\n",
    "**Usefulness in Chemical Sciences**: Visual representation of data is crucial in\n",
    "chemistry for understanding complex relationships, trends, and patterns. Matplotlib\n",
    "enables chemists to visualize experimental results, such as reaction rates or\n",
    "concentration changes over time, and to compare theoretical models with experimental\n",
    "data. It's also used in teaching to help explain complex concepts through visual aids.\n",
    "\n",
    "\n",
    "Let's plot some chemically-inspired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = ['Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne']\n",
    "atomic_radii = [152, 112, 88, 77, 70, 66, 64, 58]  # in pm\n",
    "\n",
    "# Create a plot. Use a 'o' marker to plot scatter points\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(elements, atomic_radii, marker='o', linestyle='-', color='b')\n",
    "ax.set_title('Atomic Radii of the Elements in the Second Period')\n",
    "ax.set_xlabel('Element')\n",
    "ax.set_ylabel('Atomic Radii (pm)')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = ['H', 'He', 'Li', 'Be']\n",
    "ionization_energies = [13.6, 24.6, 5.39, 9.32]  # in eV\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(elements, ionization_energies, color='green')\n",
    "ax.set_title('First Ionization Energies of Elements')\n",
    "ax.set_xlabel('Element')\n",
    "ax.set_ylabel('Ionization Energy (eV)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from before\n",
    "file_path = \"molecular_data.txt\"\n",
    "df = pd.read_csv(file_path, names=[\"molecule\", \"weight\", \"boiling_point_celsius\"], skiprows=1)\n",
    "df\n",
    "\n",
    "# Create a sub-dataframe for the linear hydrocarbons. First, let's create a dictionary\n",
    "# to map the names to the number of carbons.\n",
    "hydrocarbons = {\n",
    "    \"Methane\": 1,\n",
    "    \"Ethane\": 2,\n",
    "    \"Propane\": 3,\n",
    "    \"Butane\": 4,\n",
    "    \"Pentane\": 5,\n",
    "    \"Hexane\": 6,\n",
    "    \"Heptane\": 7,\n",
    "    \"Octane\": 8,\n",
    "    \"Nonane\": 9,\n",
    "    \"Decane\": 10,\n",
    "\n",
    "}\n",
    "hcarbons_df = df[df[\"molecule\"].isin(hydrocarbons.keys())]\n",
    "\n",
    "# Add this as a column in the dataframe\n",
    "hcarbons_df[\"num_carbons\"] = [hydrocarbons[name] for name in hcarbons_df[\"molecule\"]]\n",
    "display(hcarbons_df)\n",
    "\n",
    "# Plot the molecular weight against the number of carbons\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(hcarbons_df[\"num_carbons\"], hcarbons_df[\"weight\"])\n",
    "\n",
    "# Add axes titles and labels\n",
    "ax.set_xlabel(\"Number of carbons\")\n",
    "ax.set_ylabel(\"Molecular Weight (g/mol)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot both the molecular weight and boiling point on the same plot, using a secondary\n",
    "# axis\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(hcarbons_df[\"num_carbons\"], hcarbons_df[\"weight\"], label=\"Molecular Weight (g/mol)\")\n",
    "ax.scatter(hcarbons_df[\"num_carbons\"], hcarbons_df[\"boiling_point_celsius\"], label=\"Boiling Point (°C)\")\n",
    "\n",
    "# Add a title and labels\n",
    "ax.set_xlabel(\"Number of carbons in hydrocarbon\")\n",
    "ax.set_ylabel(\"Molecular Weight (g/mol)\")\n",
    "ax.set_ylabel(\"Boiling Point (°C)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot both the molecular weight and boiling point on the same plot, using a secondary\n",
    "# axis\n",
    "plt.scatter(hcarbons_df[\"num_carbons\"], hcarbons_df[\"weight\"], label=\"Molecular Weight (g/mol)\")\n",
    "plt.scatter(hcarbons_df[\"num_carbons\"], hcarbons_df[\"boiling_point_celsius\"], label=\"Boiling Point (°C)\")\n",
    "\n",
    "# Add a title and labels\n",
    "plt.xlabel(\"Number of carbons in hydrocarbon\")\n",
    "plt.ylabel(\"Molecular Weight (g/mol)\")\n",
    "plt.ylabel(\"Boiling Point (°C)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn! \n",
    "\n",
    "1. Use a `Path` object to define the path to the reaction yield file from last week:\n",
    "   \"reaction_yields.txt\". This will be stored at relative path `../week_03/reaction_yields.txt`\n",
    "2. Create a `pandas` DataFrame by loading the data from this path\n",
    "2. Calculate the percentage yield, and add it as a new column in the DataFrame\n",
    "3. Plot a bar graph with `matplotlib`, where the x axis is the name of the scientist and\n",
    "   the y axis is the percentage yield.\n",
    "\n",
    "**Hint**: you'll need to inpsect the file to see what the ***delimiter*** is. Use the\n",
    "`pd.read_csv(...)` function with the `sep` (for the delimiter) and `skiprows` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about some real data?\n",
    "\n",
    "Do you have some data from a recent lab experiment, in `.csv`, `.xlsx`, or `.txt` file\n",
    "format?\n",
    "\n",
    "If so and if you have time, try to read it into a pandas DataFrame and make some plots.\n",
    "The TAs would love to hear about your experiments - speak to us and we'll see what cool\n",
    "plots we can make with what you've learned already :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: `scipy` and `seaborn`\n",
    "\n",
    "Two packages that have not been introduced here, but provide extra functionality on top\n",
    "of `numpy` and `matplotlib`, respectively, are `scipy` and `seaborn`. So that you're\n",
    "aware of them, here are short descriptions and code examples.\n",
    "\n",
    "#### SciPy: Enhancing NumPy for Scientific Computing\n",
    "\n",
    "While NumPy provides the foundational array data structure and basic operations for\n",
    "numerical computing in Python, SciPy builds upon this foundation to offer a\n",
    "comprehensive collection of algorithms for scientific computing. SciPy, short for\n",
    "Scientific Python, is a library that provides modules for optimization, linear algebra,\n",
    "integration, interpolation, special functions, FFT, signal and image processing, ODE\n",
    "solvers, and other tasks common in science and engineering. \n",
    "\n",
    "Essentially, SciPy takes the capabilities of NumPy to the next level by adding a vast\n",
    "array of mathematical functions and algorithms for data manipulation and analysis. It's\n",
    "particularly valuable for tasks that require complex mathematical computations, such as\n",
    "solving differential equations, finding numerical integrals, or optimizing functions.\n",
    "\n",
    "This example demonstrates how SciPy can be used to solve a linear system of equations,\n",
    "which is a common task in scientific computing. The system of equations we'll solve is:\n",
    "\n",
    "3x + 2y = 5\n",
    "\n",
    "4x - y = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the lines defined by the equations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the x values\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y1 = 0.5 * (5 - 3 * x)\n",
    "y2 = 4 * x - 2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y1)\n",
    "ax.plot(x, y2)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-comment and run to install scipy\n",
    "# !pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "# Coefficients of the equations\n",
    "A = np.array([[3, 2], [4, -1]])\n",
    "\n",
    "# Right-hand side values\n",
    "b = np.array([5, 2])\n",
    "\n",
    "# Solving for x and y\n",
    "x_intersect, y_intersect = linalg.solve(A, b)\n",
    "\n",
    "print(f'Solution: x = {x_intersect}, y = {y_intersect}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-plot the figure from above\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y1 = 0.5 * (5 - 3 * x)\n",
    "y2 = 4 * x - 2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y1)\n",
    "ax.plot(x, y2)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "\n",
    "# Add the solution to the plot\n",
    "ax.axvline(x_intersect, linestyle=\"dashed\", color=\"gray\", label=f\"x = {x_intersect:.2f}\")\n",
    "ax.axhline(y_intersect, linestyle=\"dotted\", color=\"gray\", label=f\"y = {y_intersect:.2f}\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn: Statistical Data Visualization\n",
    "\n",
    "Matplotlib is an incredibly flexible plotting library, allowing for the creation of a\n",
    "wide range of static, animated, and interactive plots. Seaborn builds on Matplotlib by\n",
    "providing a high-level interface for drawing attractive and informative statistical\n",
    "graphics. It is specifically designed to work well with pandas DataFrames, making it\n",
    "easier to visualize data from these structures. \n",
    "\n",
    "Seaborn simplifies the process of creating complex visualizations like heat maps, time\n",
    "series, and violin plots. It automatically applies default themes that are aesthetically\n",
    "pleasing and offers a rich set of options for customizing plots. Additionally, Seaborn\n",
    "includes functions for fitting and visualizing linear regression models, making it an\n",
    "invaluable tool for data analysis and exploration. By abstracting the complexity of\n",
    "Matplotlib, Seaborn enables researchers and data scientists to generate insights into\n",
    "their data through visualizations with less code.\n",
    "\n",
    "This example shows how Seaborn can be used to create a distribution plot, which is\n",
    "useful for visualizing the distribution of a dataset. We'll generate a random dataset\n",
    "using NumPy and then visualize it with Seaborn's distplot, which combines a histogram\n",
    "with a kernel density estimate (KDE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-comment and run to install seaborn\n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a random dataset\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# Create a distribution plot\n",
    "sns.set(style=\"whitegrid\")  # Set the style for the plot\n",
    "sns.distplot(data, bins=30, kde=True, color=\"blue\")\n",
    "\n",
    "plt.title('Distribution Plot of Random Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
